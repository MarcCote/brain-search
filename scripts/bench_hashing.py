#!/usr/bin/env python
from __future__ import division

#import os
#from os.path import join as pjoin

import json
import time
import numpy as np
#import pylab as plt
#import itertools
#import nibabel as nib

#from itertools import izip, chain
#import brainsearch.vizu as vizu

#import brainsearch.utils as brainutil
#from brainsearch.imagespeed import blockify
from brainsearch.brain_database import BrainDatabaseManager
from brainsearch.brain_data import brain_data_factory

# from nearpy.hashes import RandomBinaryProjections, RandomPCABinaryProjections, PCABinaryProjections, SpectralHashing
# from nearpy.distances import EuclideanDistance
# from nearpy.filters import NearestFilter, DistanceThresholdFilter
# from nearpy.utils import chunk, ichunk

from brainsearch.brain_processing import BrainPipelineProcessing, BrainNormalization, BrainResampling
from brainsearch import framework
from brainsearch.utils import Timer

import argparse

#PORT = 4242
PORT = 6379
OFFSET = 0.01


def build_subcommand_list(subparser):
    DESCRIPTION = "List available brain databases."

    p = subparser.add_parser("list",
                             description=DESCRIPTION,
                             help=DESCRIPTION,
                             formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    p.add_argument('name', type=str, nargs='?', help='name of the brain database')
    p.add_argument('-v', action='store_true', help='display more information about brain databases')
    p.add_argument('-f', action='store_true', help='check integrity of brain databases')


def build_subcommand_clear(subparser):
    DESCRIPTION = "Clear brain databases."

    p = subparser.add_parser("clear",
                             description=DESCRIPTION,
                             help=DESCRIPTION,
                             formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    p.add_argument('names', metavar="name", type=str, nargs="*", help='name of the brain database to delete')
    p.add_argument('-f', action='store_true', help='clear also metadata')


def build_subcommand_init(subparser):
    DESCRIPTION = "Build a new brain database (nearpy's engine)."

    p = subparser.add_parser("init",
                             description=DESCRIPTION,
                             help=DESCRIPTION)

    p.add_argument('name', type=str, help='name of the brain database')
    p.add_argument('shape', metavar="X,Y,...", type=str, help="data's shape or patch shape")
    p.add_argument('--LSH', metavar="N", type=int, help='numbers of random projections')
    p.add_argument('--LSH_PCA', metavar="N", type=int, help='numbers of random projections in PCA space')
    p.add_argument('--PCA', metavar="K", type=int, help='use K eigenvectors')
    p.add_argument('--SH', metavar="K", type=int, help='length of hash codes generated by Spectral Hashing')
    p.add_argument('--trainset', type=str, help='JSON file use to "train" PCA')
    p.add_argument('--pca_pkl', type=str, help='pickle file containing the PCA information of the data')
    p.add_argument('--bounds_pkl', type=str, help='pickle file containing the bounds used by spectral hashing')


def build_subcommand_add(subparser):
    DESCRIPTION = "Add data to an existing brain database."

    p = subparser.add_parser("add",
                             description=DESCRIPTION,
                             help=DESCRIPTION,
                             formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    p.add_argument('name', type=str, help='name of the brain database')
    p.add_argument('config', type=str, help='contained in a JSON file')


def build_subcommand_vizu(subparser):
    DESCRIPTION = "Run some vizu for a brain given an existing brain database."

    p = subparser.add_parser("vizu",
                             description=DESCRIPTION,
                             help=DESCRIPTION,
                             formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    p.add_argument('name', type=str, help='name of the brain database')
    p.add_argument('config', type=str, help='contained in a JSON file')


def build_subcommand_check(subparser):
    DESCRIPTION = "Check candidates distribution given an existing brain database."

    p = subparser.add_parser("check",
                             description=DESCRIPTION,
                             help=DESCRIPTION,
                             formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    p.add_argument('names', type=str, nargs='*', help='name of the brain database')
    #p.add_argument('-m', dest="min_nonempty", type=int, help='consider only patches having this minimum number of non-empty voxels')


def buildArgsParser():
    DESCRIPTION = "Script to perform brain searches."
    p = argparse.ArgumentParser(description=DESCRIPTION)

    p.add_argument('--storage', type=str, default="redis", help='which storage to use: redis, memory, file')

    p.add_argument('--use_spatial_code', action='store_true', help='include spatial position of a patch in hashcode')
    p.add_argument('-m', dest="min_nonempty", type=float, help='consider only patches having this minimum percent of non-empty voxels')
    p.add_argument('-N', type=int, help='use N brains', default=10)
    p.add_argument('-r', dest="resampling_factor", type=float, help='resample image before processing', default=1.)
    p.add_argument('--norm', dest="do_normalization", action="store_true", help='perform histogram equalization')

    subparser = p.add_subparsers(title="brain_search commands", metavar="", dest="command")
    build_subcommand_list(subparser)
    build_subcommand_init(subparser)
    build_subcommand_add(subparser)
    build_subcommand_vizu(subparser)
    build_subcommand_check(subparser)
    build_subcommand_clear(subparser)

    return p


def main(brain_manager=None):
    parser = buildArgsParser()
    args = parser.parse_args()

    if brain_manager is None:
        brain_manager = BrainDatabaseManager(args.storage)

    # Build processing pipeline
    pipeline = BrainPipelineProcessing()
    if args.do_normalization:
        pipeline.add(BrainNormalization(type=0))
    if args.resampling_factor > 1:
        pipeline.add(BrainResampling(args.resampling_factor))

    if args.command == "list":
        framework.list(brain_manager, args.name, verbose=args.v, check_integrity=args.f)
    elif args.command == "clear":
        with Timer("Clearing all"):
            framework.clear(brain_manager, args.names, force=args.f)

    elif args.command == "init":
        print "Creating brain database {}...".format(args.name)
        if args.name in brain_manager:
            print ("This database already exists. Please use command "
                   "'brain_search.py --storage {} clear -f {}' before.".format(brain_manager.storage.name, args.name))
            return

        start = time.time()
        patch_shape = tuple(map(int, args.shape.split(",")))

        def _get_all_patches():
            config = json.load(open(args.trainset))
            brain_data = brain_data_factory(config, pipeline=pipeline)
            for brain_id, brain in enumerate(brain_data):
                print "ID: {0}/{1}".format(brain_id, len(brain_data))
                patches, positions = brain.extract_patches(patch_shape, min_nonempty=args.min_nonempty, with_positions=True)
                vectors = patches.reshape((-1, np.prod(patch_shape)))

                if args.use_spatial_code:
                    # Normalize position
                    pos_normalized = positions / np.array(brain.infos['img_shape'], dtype="float32")
                    vectors = np.c_[pos_normalized, vectors]

                yield vectors

        dimension = np.prod(patch_shape)
        if args.use_spatial_code:
            dimension += len(patch_shape)

        hash_params = {}
        if args.SH is not None:
            hashtype, nbits = "SH", args.SH
            hash_params['trainset'] = _get_all_patches
            hash_params['pca_pkl'] = args.pca_pkl
            hash_params['bounds_pkl'] = args.bounds_pkl
        elif args.PCA is not None:
            hashtype, nbits = "PCA", args.PCA
            hash_params['trainset'] = _get_all_patches
            hash_params['pca_pkl'] = args.pca_pkl
        elif args.LSH is not None:
            hashtype, nbits = "LSH", args.LSH
        else:
            print "Must provide one of the following options: --SH, --LSH or --PCA"
            return

        hashing = framework.hashing_factory(hashtype, dimension, nbits, **hash_params)
        framework.init(brain_manager, args.name, patch_shape, hashing)

        print "Created in {0:.2f} sec.".format(time.time()-start)

    elif args.command == "add":
        config = json.load(open(args.config))
        brain_data = brain_data_factory(config, pipeline=pipeline)
        framework.add(brain_manager, args.name, brain_data,
                      min_nonempty=args.min_nonempty,
                      use_spatial_code=args.use_spatial_code)

    elif args.command == "check":
        for name in args.names:
            framework.check(brain_manager, name,
                            use_spatial_code=args.use_spatial_code)

    return brain_manager


if __name__ == '__main__':
    db_manager = main()
